{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1382412,"sourceType":"datasetVersion","datasetId":806606},{"sourceId":7449449,"sourceType":"datasetVersion","datasetId":4336196}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection, naive_bayes, svm\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\ntrain_url = '/kaggle/input/80-20ratiofinal/train8020.csv'\ntest_url = '/kaggle/input/80-20ratiofinal/test8020.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T00:23:40.001241Z","iopub.execute_input":"2024-01-22T00:23:40.003236Z","iopub.status.idle":"2024-01-22T00:23:43.692513Z","shell.execute_reply.started":"2024-01-22T00:23:40.003165Z","shell.execute_reply":"2024-01-22T00:23:43.690842Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"STOPWORDS = set([word.strip() for word in stop_words_df['words']])\nimport re\ndef preprocess(x):\n    html_pattern = re.compile('<.*?>')\n    x = html_pattern.sub(r'', x)\n    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n    return x\ndf_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\ndf_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))\n\nEncoder = LabelEncoder()\nTrain_Y = Encoder.fit_transform(df_train.Category)\nTest_Y = Encoder.fit_transform(df_test.Category)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T00:26:22.180917Z","iopub.execute_input":"2024-01-22T00:26:22.181915Z","iopub.status.idle":"2024-01-22T00:26:22.362983Z","shell.execute_reply.started":"2024-01-22T00:26:22.181848Z","shell.execute_reply":"2024-01-22T00:26:22.361790Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=5000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])\nmodel = XGBClassifier(\n    n_estimators=100,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T00:26:31.428528Z","iopub.execute_input":"2024-01-22T00:26:31.429182Z","iopub.status.idle":"2024-01-22T00:26:32.044026Z","shell.execute_reply.started":"2024-01-22T00:26:31.429129Z","shell.execute_reply":"2024-01-22T00:26:32.042424Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T00:26:35.502317Z","iopub.execute_input":"2024-01-22T00:26:35.502783Z","iopub.status.idle":"2024-01-22T00:26:42.893176Z","shell.execute_reply.started":"2024-01-22T00:26:35.502750Z","shell.execute_reply":"2024-01-22T00:26:42.891770Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5278    0.1313    0.2102       579\n           1     0.4677    0.7495    0.5760      1912\n           2     0.0000    0.0000    0.0000        88\n           3     0.5200    0.0312    0.0588       417\n           4     0.5064    0.4472    0.4750      2026\n\n    accuracy                         0.4835      5022\n   macro avg     0.4044    0.2718    0.2640      5022\nweighted avg     0.4864    0.4835    0.4400      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=5000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])\nmodel = XGBClassifier(\n    n_estimators=300,  # Number of boosting rounds (trees)\n    learning_rate=0.05,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:30:04.246665Z","iopub.execute_input":"2024-01-22T00:30:04.247230Z","iopub.status.idle":"2024-01-22T00:30:04.870941Z","shell.execute_reply.started":"2024-01-22T00:30:04.247194Z","shell.execute_reply":"2024-01-22T00:30:04.869116Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:30:11.586141Z","iopub.execute_input":"2024-01-22T00:30:11.586625Z","iopub.status.idle":"2024-01-22T00:30:34.953321Z","shell.execute_reply.started":"2024-01-22T00:30:11.586566Z","shell.execute_reply":"2024-01-22T00:30:34.950694Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5195    0.1382    0.2183       579\n           1     0.4714    0.7244    0.5711      1912\n           2     0.0000    0.0000    0.0000        88\n           3     0.5143    0.0432    0.0796       417\n           4     0.5050    0.4724    0.4881      2026\n\n    accuracy                         0.4859      5022\n   macro avg     0.4020    0.2756    0.2714      5022\nweighted avg     0.4858    0.4859    0.4462      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=5000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])\nmodel = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.05,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.7,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.7,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:30:48.188722Z","iopub.execute_input":"2024-01-22T00:30:48.189177Z","iopub.status.idle":"2024-01-22T00:30:48.755066Z","shell.execute_reply.started":"2024-01-22T00:30:48.189144Z","shell.execute_reply":"2024-01-22T00:30:48.753935Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:30:52.722617Z","iopub.execute_input":"2024-01-22T00:30:52.723293Z","iopub.status.idle":"2024-01-22T00:31:28.552301Z","shell.execute_reply.started":"2024-01-22T00:30:52.723237Z","shell.execute_reply":"2024-01-22T00:31:28.550701Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5497    0.1623    0.2507       579\n           1     0.4811    0.7055    0.5721      1912\n           2     0.0000    0.0000    0.0000        88\n           3     0.4035    0.0552    0.0970       417\n           4     0.5050    0.4961    0.5005      2026\n\n    accuracy                         0.4920      5022\n   macro avg     0.3879    0.2838    0.2841      5022\nweighted avg     0.4838    0.4920    0.4567      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=5000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])\nmodel = XGBClassifier(\n    n_estimators=700,  # Number of boosting rounds (trees)\n    learning_rate=0.05,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.7,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.7,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:31:28.555048Z","iopub.execute_input":"2024-01-22T00:31:28.555480Z","iopub.status.idle":"2024-01-22T00:31:29.122756Z","shell.execute_reply.started":"2024-01-22T00:31:28.555444Z","shell.execute_reply":"2024-01-22T00:31:29.121175Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:31:29.124382Z","iopub.execute_input":"2024-01-22T00:31:29.125359Z","iopub.status.idle":"2024-01-22T00:32:23.303686Z","shell.execute_reply.started":"2024-01-22T00:31:29.125314Z","shell.execute_reply":"2024-01-22T00:32:23.302388Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5301    0.1675    0.2546       579\n           1     0.4862    0.6977    0.5730      1912\n           2     0.0000    0.0000    0.0000        88\n           3     0.3836    0.0671    0.1143       417\n           4     0.5084    0.5074    0.5079      2026\n\n    accuracy                         0.4952      5022\n   macro avg     0.3816    0.2880    0.2900      5022\nweighted avg     0.4832    0.4952    0.4619      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=10000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])\nmodel = XGBClassifier(\n    n_estimators=700,  # Number of boosting rounds (trees)\n    learning_rate=0.05,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.7,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.7,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:32:23.307027Z","iopub.execute_input":"2024-01-22T00:32:23.307626Z","iopub.status.idle":"2024-01-22T00:32:23.883397Z","shell.execute_reply.started":"2024-01-22T00:32:23.307576Z","shell.execute_reply":"2024-01-22T00:32:23.881688Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:32:23.885339Z","iopub.execute_input":"2024-01-22T00:32:23.885732Z","iopub.status.idle":"2024-01-22T00:33:26.327165Z","shell.execute_reply.started":"2024-01-22T00:32:23.885701Z","shell.execute_reply":"2024-01-22T00:33:26.325938Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5208    0.1727    0.2594       579\n           1     0.4939    0.6972    0.5782      1912\n           2     0.0000    0.0000    0.0000        88\n           3     0.3218    0.0671    0.1111       417\n           4     0.5161    0.5207    0.5184      2026\n\n    accuracy                         0.5010      5022\n   macro avg     0.3705    0.2916    0.2934      5022\nweighted avg     0.4830    0.5010    0.4684      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=10000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])\nmodel = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.7,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.7,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:33:26.329031Z","iopub.execute_input":"2024-01-22T00:33:26.330301Z","iopub.status.idle":"2024-01-22T00:33:26.895189Z","shell.execute_reply.started":"2024-01-22T00:33:26.330249Z","shell.execute_reply":"2024-01-22T00:33:26.894061Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:33:26.898367Z","iopub.execute_input":"2024-01-22T00:33:26.899351Z","iopub.status.idle":"2024-01-22T00:34:10.042052Z","shell.execute_reply.started":"2024-01-22T00:33:26.899299Z","shell.execute_reply":"2024-01-22T00:34:10.039801Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.4978    0.1934    0.2786       579\n           1     0.4963    0.6752    0.5721      1912\n           2     0.0000    0.0000    0.0000        88\n           3     0.3069    0.0743    0.1197       417\n           4     0.5160    0.5336    0.5246      2026\n\n    accuracy                         0.5008      5022\n   macro avg     0.3634    0.2953    0.2990      5022\nweighted avg     0.4800    0.5008    0.4715      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=10000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])\nmodel = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.05,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.7,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.7,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:34:10.043652Z","iopub.execute_input":"2024-01-22T00:34:10.044169Z","iopub.status.idle":"2024-01-22T00:34:10.620664Z","shell.execute_reply.started":"2024-01-22T00:34:10.044136Z","shell.execute_reply":"2024-01-22T00:34:10.619254Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:36:49.088953Z","iopub.execute_input":"2024-01-22T00:36:49.089499Z","iopub.status.idle":"2024-01-22T00:37:33.899546Z","shell.execute_reply.started":"2024-01-22T00:36:49.089462Z","shell.execute_reply":"2024-01-22T00:37:33.898544Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5287    0.1589    0.2444       579\n           1     0.4890    0.7076    0.5783      1912\n           2     0.0000    0.0000    0.0000        88\n           3     0.3803    0.0647    0.1107       417\n           4     0.5149    0.5109    0.5129      2026\n\n    accuracy                         0.4992      5022\n   macro avg     0.3826    0.2884    0.2892      5022\nweighted avg     0.4864    0.4992    0.4645      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:40:41.174027Z","iopub.execute_input":"2024-01-22T00:40:41.174508Z","iopub.status.idle":"2024-01-22T00:40:41.180727Z","shell.execute_reply.started":"2024-01-22T00:40:41.174469Z","shell.execute_reply":"2024-01-22T00:40:41.179333Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('tfidf_vect', TfidfVectorizer()),\n    ('xgb', XGBClassifier())\n])\n\n# Parameter grid for hyperparameter tuning:\nparam_grid = {\n    'tfidf_vect__max_features': [5000],\n    'tfidf_vect__ngram_range': [(1, 2)],  # Consider bigrams\n    'xgb__n_estimators': [500, 700],\n    'xgb__learning_rate': [0.05, 0.1],\n    'xgb__max_depth': [4, 6],\n    'xgb__subsample': [0.7, 0.8],\n    'xgb__colsample_bytree': [0.7, 0.8]\n}\n\n# Perform grid search to find optimal hyperparameters:\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, error_score='raise')\ngrid_search.fit(df_train['Comment'], df_train['Error'])  # Pass raw text data\n\n# Access best model and parameters:\nbest_model = grid_search.best_estimator_\nbest_params = grid_search.best_params_\nprint(best_params)\n\n# Make predictions on test set:\ny_pred = best_model.predict(df_test['Comment'])\n\n# Evaluate performance:\nprint(metrics.classification_report(df_test['Error'], y_pred, digits=4))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T00:41:42.608283Z","iopub.execute_input":"2024-01-22T00:41:42.608904Z","iopub.status.idle":"2024-01-22T00:59:24.686487Z","shell.execute_reply.started":"2024-01-22T00:41:42.608836Z","shell.execute_reply":"2024-01-22T00:59:24.684665Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Perform grid search to find optimal hyperparameters:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mComment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mError\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass raw text data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Access best model and parameters:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('tfidf_vect', TfidfVectorizer()),\n    ('xgb', XGBClassifier())\n])\n\n# Parameter grid for hyperparameter tuning:\nparam_grid = {\n    'tfidf_vect__max_features': [10000],\n    'tfidf_vect__ngram_range': [(1, 2)],  # Consider bigrams\n    'xgb__n_estimators': [500, 700],\n    'xgb__learning_rate': [0.05, 0.1],\n    'xgb__max_depth': [4],\n    'xgb__subsample': [0.7],\n    'xgb__colsample_bytree': [0.7]\n}\n\n# Perform grid search to find optimal hyperparameters:\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, error_score='raise')\ngrid_search.fit(df_train['Comment'], df_train['Error'])  # Pass raw text data\n\n# Access best model and parameters:\nbest_model = grid_search.best_estimator_\nbest_params = grid_search.best_params_\nprint(best_params)\n\n# Make predictions on test set:\ny_pred = best_model.predict(df_test['Comment'])\n\n# Evaluate performance:\nprint(metrics.classification_report(df_test['Error'], y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T01:07:38.335467Z","iopub.execute_input":"2024-01-22T01:07:38.335999Z","iopub.status.idle":"2024-01-22T01:11:36.157496Z","shell.execute_reply.started":"2024-01-22T01:07:38.335949Z","shell.execute_reply":"2024-01-22T01:11:36.156181Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"{'tfidf_vect__max_features': 10000, 'tfidf_vect__ngram_range': (1, 2), 'xgb__colsample_bytree': 0.7, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 4, 'xgb__n_estimators': 500, 'xgb__subsample': 0.7}\n              precision    recall  f1-score   support\n\n           0     0.5350    0.3075    0.3906      1912\n           1     0.6625    0.8357    0.7391      3110\n\n    accuracy                         0.6346      5022\n   macro avg     0.5988    0.5716    0.5648      5022\nweighted avg     0.6140    0.6346    0.6064      5022\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# for 10k old","metadata":{}},{"cell_type":"code","source":"print(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"tags":[]},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n\n\n           0     0.9455    0.3291    0.4883       158\n\n           1     0.6075    0.9723    0.7478      1157\n\n           2     0.4783    0.0859    0.1457       128\n\n           3     0.5000    0.0145    0.0282        69\n\n           4     0.4937    0.0782    0.1349       499\n\n\n\n    accuracy                         0.6106      2011\n\n   macro avg     0.6050    0.2960    0.3090      2011\n\nweighted avg     0.5939    0.6106    0.5123      2011\n\n\n"}]}]}