{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1382412,"sourceType":"datasetVersion","datasetId":806606},{"sourceId":7443950,"sourceType":"datasetVersion","datasetId":4332835}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection, naive_bayes, svm\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\ntrain_url = '/kaggle/input/please/train_shuffled.csv'\ntest_url = '/kaggle/input/please/test_shuffled.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:36:21.406433Z","iopub.execute_input":"2024-01-20T22:36:21.406863Z","iopub.status.idle":"2024-01-20T22:36:21.782175Z","shell.execute_reply.started":"2024-01-20T22:36:21.406813Z","shell.execute_reply":"2024-01-20T22:36:21.781190Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"STOPWORDS = set([word.strip() for word in stop_words_df['words']])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:36:24.349836Z","iopub.execute_input":"2024-01-20T22:36:24.351005Z","iopub.status.idle":"2024-01-20T22:36:24.361028Z","shell.execute_reply.started":"2024-01-20T22:36:24.350961Z","shell.execute_reply":"2024-01-20T22:36:24.360176Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess(x):\n    html_pattern = re.compile('<.*?>')\n    x = html_pattern.sub(r'', x)\n    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n    return x\ndf_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\ndf_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:36:57.697325Z","iopub.execute_input":"2024-01-20T22:36:57.697727Z","iopub.status.idle":"2024-01-20T22:36:57.823217Z","shell.execute_reply.started":"2024-01-20T22:36:57.697695Z","shell.execute_reply":"2024-01-20T22:36:57.822124Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"Encoder = LabelEncoder()\nTrain_Y = Encoder.fit_transform(df_train.Error)\nTest_Y = Encoder.fit_transform(df_test.Error)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:37:01.159664Z","iopub.execute_input":"2024-01-20T22:37:01.160053Z","iopub.status.idle":"2024-01-20T22:37:01.168986Z","shell.execute_reply.started":"2024-01-20T22:37:01.160020Z","shell.execute_reply":"2024-01-20T22:37:01.168135Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=10000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:37:13.430985Z","iopub.execute_input":"2024-01-20T22:37:13.431453Z","iopub.status.idle":"2024-01-20T22:37:13.982036Z","shell.execute_reply.started":"2024-01-20T22:37:13.431414Z","shell.execute_reply":"2024-01-20T22:37:13.980905Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=700,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:39:42.696876Z","iopub.execute_input":"2024-01-20T22:39:42.697234Z","iopub.status.idle":"2024-01-20T22:39:42.703307Z","shell.execute_reply.started":"2024-01-20T22:39:42.697208Z","shell.execute_reply":"2024-01-20T22:39:42.701762Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:39:45.778548Z","iopub.execute_input":"2024-01-20T22:39:45.778919Z","iopub.status.idle":"2024-01-20T22:40:14.254374Z","shell.execute_reply.started":"2024-01-20T22:39:45.778890Z","shell.execute_reply":"2024-01-20T22:40:14.253373Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=700, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=700, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=700, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = model.predict(Test_X_Tfidf)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:40:36.488263Z","iopub.execute_input":"2024-01-20T22:40:36.488640Z","iopub.status.idle":"2024-01-20T22:40:36.684746Z","shell.execute_reply.started":"2024-01-20T22:40:36.488612Z","shell.execute_reply":"2024-01-20T22:40:36.683780Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:40:39.367710Z","iopub.execute_input":"2024-01-20T22:40:39.368427Z","iopub.status.idle":"2024-01-20T22:40:39.392259Z","shell.execute_reply.started":"2024-01-20T22:40:39.368384Z","shell.execute_reply":"2024-01-20T22:40:39.390986Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5576    0.3494    0.4296      1926\n           1     0.6787    0.8321    0.7476      3181\n\n    accuracy                         0.6501      5107\n   macro avg     0.6181    0.5908    0.5886      5107\nweighted avg     0.6330    0.6501    0.6277      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-20T01:35:34.257702Z","iopub.execute_input":"2024-01-20T01:35:34.258152Z","iopub.status.idle":"2024-01-20T01:35:35.162076Z","shell.execute_reply.started":"2024-01-20T01:35:34.258119Z","shell.execute_reply":"2024-01-20T01:35:35.160475Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=700,  # Number of boosting rounds (trees)\n    learning_rate=0.01,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T22:43:32.457521Z","iopub.execute_input":"2024-01-20T22:43:32.457931Z","iopub.status.idle":"2024-01-20T22:44:07.787132Z","shell.execute_reply.started":"2024-01-20T22:43:32.457898Z","shell.execute_reply":"2024-01-20T22:44:07.786037Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.6403    0.0924    0.1615      1926\n           1     0.6380    0.9686    0.7693      3181\n\n    accuracy                         0.6381      5107\n   macro avg     0.6392    0.5305    0.4654      5107\nweighted avg     0.6389    0.6381    0.5401      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=10000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:19:39.272834Z","iopub.execute_input":"2024-01-20T02:19:39.273273Z","iopub.status.idle":"2024-01-20T02:19:40.169164Z","shell.execute_reply.started":"2024-01-20T02:19:39.273237Z","shell.execute_reply":"2024-01-20T02:19:40.168069Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=100,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:19:42.752748Z","iopub.execute_input":"2024-01-20T02:19:42.753200Z","iopub.status.idle":"2024-01-20T02:19:44.229387Z","shell.execute_reply.started":"2024-01-20T02:19:42.753164Z","shell.execute_reply":"2024-01-20T02:19:44.228514Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5222    0.0738    0.1294      1910\n           1     0.6277    0.9585    0.7586      3112\n\n    accuracy                         0.6221      5022\n   macro avg     0.5750    0.5162    0.4440      5022\nweighted avg     0.5876    0.6221    0.5193      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.05,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.7,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.7,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T22:46:42.110502Z","iopub.execute_input":"2024-01-20T22:46:42.110920Z","iopub.status.idle":"2024-01-20T22:47:01.771886Z","shell.execute_reply.started":"2024-01-20T22:46:42.110876Z","shell.execute_reply":"2024-01-20T22:47:01.770869Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5905    0.2321    0.3332      1926\n           1     0.6600    0.9025    0.7624      3181\n\n    accuracy                         0.6497      5107\n   macro avg     0.6252    0.5673    0.5478      5107\nweighted avg     0.6338    0.6497    0.6006      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,      # Increased boosting rounds\n    learning_rate=0.05,    # Lower learning rate\n    max_depth=5,           # Increased maximum depth\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,         # L1 regularization term\n    reg_lambda=0.1,        # L2 regularization term\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:09:23.697730Z","iopub.execute_input":"2024-01-20T23:09:23.698972Z","iopub.status.idle":"2024-01-20T23:09:44.230688Z","shell.execute_reply.started":"2024-01-20T23:09:23.698923Z","shell.execute_reply":"2024-01-20T23:09:44.229589Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.6036    0.1890    0.2879      1926\n           1     0.6532    0.9249    0.7656      3181\n\n    accuracy                         0.6473      5107\n   macro avg     0.6284    0.5569    0.5268      5107\nweighted avg     0.6345    0.6473    0.5855      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,      # Increased boosting rounds\n    learning_rate=0.01,    # Lower learning rate\n    max_depth=4,           # Increased maximum depth\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,         # L1 regularization term\n    reg_lambda=0.1,        # L2 regularization term\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:19:12.122171Z","iopub.execute_input":"2024-01-20T23:19:12.122571Z","iopub.status.idle":"2024-01-20T23:19:29.438655Z","shell.execute_reply.started":"2024-01-20T23:19:12.122516Z","shell.execute_reply":"2024-01-20T23:19:29.437559Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.6538    0.0353    0.0670      1926\n           1     0.6286    0.9887    0.7686      3181\n\n    accuracy                         0.6291      5107\n   macro avg     0.6412    0.5120    0.4178      5107\nweighted avg     0.6381    0.6291    0.5040      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.7,\n    colsample_bytree=0.7,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=3,   # Experiment with different values\n    gamma=0.05,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:20:20.259110Z","iopub.execute_input":"2024-01-20T23:20:20.259501Z","iopub.status.idle":"2024-01-20T23:20:33.752173Z","shell.execute_reply.started":"2024-01-20T23:20:20.259469Z","shell.execute_reply":"2024-01-20T23:20:33.751182Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.6003    0.1926    0.2917      1926\n           1     0.6536    0.9224    0.7651      3181\n\n    accuracy                         0.6472      5107\n   macro avg     0.6270    0.5575    0.5284      5107\nweighted avg     0.6335    0.6472    0.5865      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=1,   # Experiment with different values\n    gamma=0.1,            # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:21:34.621428Z","iopub.execute_input":"2024-01-20T23:21:34.621838Z","iopub.status.idle":"2024-01-20T23:21:54.533682Z","shell.execute_reply.started":"2024-01-20T23:21:34.621790Z","shell.execute_reply":"2024-01-20T23:21:54.532554Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.6030    0.1869    0.2854      1926\n           1     0.6528    0.9255    0.7656      3181\n\n    accuracy                         0.6470      5107\n   macro avg     0.6279    0.5562    0.5255      5107\nweighted avg     0.6340    0.6470    0.5845      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.005,  # Lower learning rate\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=1,   # Experiment with different values\n    gamma=0.15,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:22:09.158038Z","iopub.execute_input":"2024-01-20T23:22:09.158518Z","iopub.status.idle":"2024-01-20T23:22:31.614900Z","shell.execute_reply.started":"2024-01-20T23:22:09.158478Z","shell.execute_reply":"2024-01-20T23:22:31.613961Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.6768    0.0348    0.0662      1926\n           1     0.6288    0.9899    0.7691      3181\n\n    accuracy                         0.6297      5107\n   macro avg     0.6528    0.5124    0.4176      5107\nweighted avg     0.6469    0.6297    0.5040      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.7,\n    colsample_bytree=0.7,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=3,   # Experiment with different values\n    gamma=0.05,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:30:53.231103Z","iopub.execute_input":"2024-01-20T23:30:53.231469Z","iopub.status.idle":"2024-01-20T23:31:15.853642Z","shell.execute_reply.started":"2024-01-20T23:30:53.231440Z","shell.execute_reply":"2024-01-20T23:31:15.852886Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5895    0.2565    0.3575      1926\n           1     0.6646    0.8919    0.7616      3181\n\n    accuracy                         0.6522      5107\n   macro avg     0.6270    0.5742    0.5595      5107\nweighted avg     0.6363    0.6522    0.6092      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=700,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.7,\n    colsample_bytree=0.7,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=3,   # Experiment with different values\n    gamma=0.1,            # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T23:33:50.121909Z","iopub.execute_input":"2024-01-20T23:33:50.122298Z","iopub.status.idle":"2024-01-20T23:34:19.440112Z","shell.execute_reply.started":"2024-01-20T23:33:50.122266Z","shell.execute_reply":"2024-01-20T23:34:19.439035Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5832    0.2965    0.3931      1926\n           1     0.6718    0.8717    0.7588      3181\n\n    accuracy                         0.6548      5107\n   macro avg     0.6275    0.5841    0.5760      5107\nweighted avg     0.6384    0.6548    0.6209      5107\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.01,\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=5,   # Experiment with different values\n    gamma=0.05,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:23:21.797408Z","iopub.execute_input":"2024-01-20T02:23:21.798220Z","iopub.status.idle":"2024-01-20T02:23:28.911718Z","shell.execute_reply.started":"2024-01-20T02:23:21.798183Z","shell.execute_reply":"2024-01-20T02:23:28.910787Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5344    0.0366    0.0686      1910\n           1     0.6238    0.9804    0.7625      3112\n\n    accuracy                         0.6215      5022\n   macro avg     0.5791    0.5085    0.4155      5022\nweighted avg     0.5898    0.6215    0.4986      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:25:47.028325Z","iopub.execute_input":"2024-01-20T02:25:47.028706Z","iopub.status.idle":"2024-01-20T02:25:55.665633Z","shell.execute_reply.started":"2024-01-20T02:25:47.028677Z","shell.execute_reply":"2024-01-20T02:25:55.664676Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5249    0.2644    0.3517      1910\n           1     0.6539    0.8531    0.7404      3112\n\n    accuracy                         0.6292      5022\n   macro avg     0.5894    0.5588    0.5460      5022\nweighted avg     0.6049    0.6292    0.5925      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=6,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:27:39.722162Z","iopub.execute_input":"2024-01-20T02:27:39.722549Z","iopub.status.idle":"2024-01-20T02:27:54.978958Z","shell.execute_reply.started":"2024-01-20T02:27:39.722520Z","shell.execute_reply":"2024-01-20T02:27:54.977793Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5347    0.3188    0.3995      1910\n           1     0.6649    0.8297    0.7382      3112\n\n    accuracy                         0.6354      5022\n   macro avg     0.5998    0.5743    0.5689      5022\nweighted avg     0.6154    0.6354    0.6094      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=800,    # Increased boosting rounds\n    learning_rate=0.05,  # Lower learning rate\n    max_depth=7,         # Increased maximum depth\n    subsample=0.85,      # Experiment with different values\n    colsample_bytree=0.85,  # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:33:41.687539Z","iopub.execute_input":"2024-01-20T02:33:41.688029Z","iopub.status.idle":"2024-01-20T02:34:11.178081Z","shell.execute_reply.started":"2024-01-20T02:33:41.687975Z","shell.execute_reply":"2024-01-20T02:34:11.177170Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5310    0.3047    0.3872      1910\n           1     0.6617    0.8348    0.7383      3112\n\n    accuracy                         0.6332      5022\n   macro avg     0.5964    0.5698    0.5628      5022\nweighted avg     0.6120    0.6332    0.6048      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=1000,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=6,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:46:07.688639Z","iopub.execute_input":"2024-01-20T02:46:07.689184Z","iopub.status.idle":"2024-01-20T02:46:36.503222Z","shell.execute_reply.started":"2024-01-20T02:46:07.689132Z","shell.execute_reply":"2024-01-20T02:46:36.502382Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5189    0.3738    0.4346      1910\n           1     0.6720    0.7873    0.7251      3112\n\n    accuracy                         0.6300      5022\n   macro avg     0.5954    0.5805    0.5798      5022\nweighted avg     0.6138    0.6300    0.6146      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=1000,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=5,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,\n    reg_alpha=0.1,\n    reg_lambda=0.1,     # Fraction of features used for fitting each tree   # Experiment with different values    \n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:53:30.001255Z","iopub.execute_input":"2024-01-20T02:53:30.001656Z","iopub.status.idle":"2024-01-20T02:53:51.136796Z","shell.execute_reply.started":"2024-01-20T02:53:30.001620Z","shell.execute_reply":"2024-01-20T02:53:51.135500Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5168    0.3628    0.4263      1910\n           1     0.6694    0.7918    0.7255      3112\n\n    accuracy                         0.6286      5022\n   macro avg     0.5931    0.5773    0.5759      5022\nweighted avg     0.6113    0.6286    0.6117      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=7,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:56:06.427785Z","iopub.execute_input":"2024-01-20T02:56:06.428199Z","iopub.status.idle":"2024-01-20T02:56:25.011051Z","shell.execute_reply.started":"2024-01-20T02:56:06.428168Z","shell.execute_reply":"2024-01-20T02:56:25.009832Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5278    0.3335    0.4087      1910\n           1     0.6663    0.8168    0.7339      3112\n\n    accuracy                         0.6330      5022\n   macro avg     0.5970    0.5752    0.5713      5022\nweighted avg     0.6136    0.6330    0.6103      5022\n\n","output_type":"stream"}]}]}